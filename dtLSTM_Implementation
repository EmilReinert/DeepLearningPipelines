Progress Documentation:



A deep tree based model for software defect prediction - Self Implementation

- paper algorithm has most preprocesses within the LSTM Unit calculation
	-> will be extracted and fit to our modules
- data is not being embedded beforehand but rather makes use of an embedding matrix that is used within the NN processes in oder to look up the vectors
	-> The embedding is only for the actual node names and doesnt represent any AST build
	-> thats how i will process it for now but it might ignore important data?
- tree implementation will help here but LSTM unit processes will have to be adjusted (DefectTreeLSTM)

- internal PROBLEMS:
	Everything regarding the parent prediction makes sense:
	We train on clean data to see which ast child-parent configurations are the most common.
		That is done by iterating over Asts starting from the branches, predicting parent from children
		(and context) and adjusting the weights based on the diffrenece of prediction and outcome
	The resulting, trained network is then used to recurisively iterate over ast nodes and doing some
	LSTM Processes on each node, to obtain a vector which is then classified(?)
	BUT:
	- Now how is defective data used?
	- How does training and predicting differenciate?
	- How do we instanciate and train the classification process

- Paper Documentation PROBLEMS:
	- The actual defect prediction learning is not explained
	- Defect Prediction Algorithm doesnt say a lot about what it does
	- What TreeLSTM is actually used and how is it modified?? (ChildSum)
	- What is a vector representation of an AST, how can one obtain it, what does it actually stand for?


=> In order to understand the overall Functionality of the paper LUA TreeLSTM will be put aside for now, so the NN process will be simulated by an RNN and extended lateron



Future Steps for only Implementation:
(*)- Include dummy RNN (note: doesnt yet really run)
(X)- Adjust RNN Training and Predicting
( )- Research and add classification training
( )- Manage Embedding Training??
( )- Include TreeLSTM
	( )- Build and Understand TreeLSTM (ChildSum?)
	( )- Adjust Training and Predicting

Future Steps for after connecting it to COGEâ„¢
( )- Expanding data crawlings (PROMISE Dataset)



Explicit Comments:
- Defect Prediction done like the training, i.e. all child nodes of an AST are being input into the lstm and the each parent node is being predicted.
	+ Defect Prediction now becomes basically the accuracy calculation of test data
	+/- This process is now directly connected to the accuracy of the LSTM 
- Defective Data will be used as a way of finding the threshold between the accuracy/def-probability 
	- Threshold might be inaccurate





----------------------------------------------------------------------------
Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks - Reference Implemenations

- The Library consitsts of two Tasks:
	semantic relatedness | sentiment classification

  and can make use of 4 nn models, where only treelstm is interesting:
	(LSTM(Normal, bidirected) and TreeLSTM(childsum and n-ary))

- They have two different Tree Algorithms, both probably have to be adapted for defect prediction:
	- ChildSumTree: 
	- N-ary Tree LSTM:
		'can be used on tree structures where the branching factor 
		is at most N and where children are ordered'
	-> I dont really understand which has a better/suitable functionality so ill combine them?

- The Tasks don't especially fit to the Defect Prediction model; Nonetheless the label classification process from the sentiment classification might suffice for its training process
